{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### ETL Pipeline for US Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import psycopg2     ## Psycopg2 is the most popular PostgreSQL database adapter for the Python programming language.\n",
    "\n",
    "%reload_ext sql \n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta   ## for converting data to datetime format\n",
    "from pyspark.sql import types as T         ## for importing Datetime and other data types\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### 1.1 Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc\n",
    "\n",
    "\n",
    "*Our objective is to create a pipeline to process the raw data from the data repository of the client, and store the processed data in datalake and further query the data using cloud data warehouse (AWS Redshift), so that client can analyse the immigration data at scale, and generate actionable insights at faster pace.*\n",
    "\n",
    "\n",
    "#### 1.2 Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "#### 1.3 Data:\n",
    "1. I94 Immigration Data: This data comes from the US National Tourism and Trade Office. \n",
    "      The descriptions is contained in the 'I94_SAS_Labels_Descriptions.SAS'file.\n",
    "2. World Temperature Data: This dataset came from Kaggle.\n",
    "3. U.S. City Demographic Data: This data comes from OpenSoft.\n",
    "4. Airport Code Table: This is a simple table of airport codes and corresponding cities.\n",
    "\n",
    "\n",
    "#### 1.4 Architecture\n",
    "![](Images/Architecture.png)\n",
    "\n",
    "![](Images/architecture1.png)\n",
    "\n",
    "#### 1.5 High Level Description of the architecture.\n",
    "\n",
    "1. **Justification for using both EMR and Redshift:** We can query the data stored in S3 using EMR PySpark. We can do the same with the help of RedShift because we can run sql queries on different type of data in S3 directly from redshift. In case of Redshift we can do this by purely using SQL, whereas, in case of PySpark we have to use PySpark plus some SQL. Both EMR and Redshift has been used in two different phases: EMR for processing the Big Raw Data, whereas, Redshift is being used to query the processed raw data, also the query processing in Redshift is faster than Spark because the Redshift is a columnar storage database. Since we want to make it easier for the end user to query/analyse data, thus end user can simply write SQL query to get value from the redshift data warehouse.\n",
    "\n",
    "2. **Phase 1:** Since the data is very big and is of varied nature (SAS files, CSV files, and Parquet files), thus we first need to process all the data then store them in parquet format in S3. For this activity we will be using EMR PySpark. This processed data will be stored in S3. \n",
    "\n",
    "3. **Phase 2:** Further, the processed data in S3 will be copied in facts and dimensions tables in Redshift, so that it can be queried using any BI App. The result of querying from redshift can also be stored in S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create environment variable for configuration\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Special Notes: \n",
    "\n",
    "1. Once we create the **environment variables**, then we can create spark session with spark hadoop aws package, which is mean for connecting spark session with AWS using environment variables.\n",
    "\n",
    "\n",
    "2. Therefore always create environment variables first before creating spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\")  \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Define a Function to convert to upper case\n",
    "\n",
    "def to_upper_case_(df, existing_column_name, new_column_name):\n",
    "    \"\"\" \n",
    "    This function creates an additional column, which converts the existing column to upper case.\n",
    "    This function also drops the existing lower case column after conversion to upper case.\n",
    "    \n",
    "    Args:\n",
    "      df: data frame\n",
    "      existing_column_name: name of existing lower case column in data frame df.\n",
    "      new_column_name: name of new upper case column created using this function. \n",
    "      \n",
    "    \"\"\"\n",
    "    df[new_column_name] = df[existing_column_name].apply(lambda x: x.upper())\n",
    "    df.drop([existing_column_name], axis = 1, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.0 S3 Bucket paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# S3 Customer data paths\n",
    "csv_data_path = 's3a://data-store-client-ap/csv_data/'\n",
    "immig_data_path = 's3a://data-store-client-ap/sas_immi_data/'\n",
    "\n",
    "# S3 Staging path\n",
    "\n",
    "staging_path = 's3a://staging-ap/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the immigration data from S3\n",
    "df_immi = spark.read.parquet(immig_data_path+'part*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459651.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.555625e+10</td>\n",
       "      <td>00115</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459652.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.744065e+08</td>\n",
       "      <td>103</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459653.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20557.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10022016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.749482e+08</td>\n",
       "      <td>109</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459654.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.554176e+10</td>\n",
       "      <td>00103</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459655.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.554133e+10</td>\n",
       "      <td>00103</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459656.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557804e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459657.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557892e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>459658.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557874e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>459659.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557746e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>459660.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557787e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  459651.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "1  459652.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "2  459653.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "3  459654.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0       G   \n",
       "4  459655.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "5  459656.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "6  459657.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "7  459658.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "8  459659.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "9  459660.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0  20559.0    54.0      2.0    1.0  20160403     None  None       O       R   \n",
       "1  20555.0    74.0      2.0    1.0  20160403     None  None       T       O   \n",
       "2  20557.0    44.0      2.0    1.0  20160403     None  None       T       Q   \n",
       "3  20555.0    38.0      2.0    1.0  20160403     None  None       O       O   \n",
       "4      NaN    64.0      2.0    1.0  20160403     None  None       G    None   \n",
       "5      NaN    63.0      2.0    1.0  20160403     None  None       G    None   \n",
       "6  20548.0    44.0      1.0    1.0  20160403     None  None       G       I   \n",
       "7  20548.0    39.0      1.0    1.0  20160403     None  None       G       I   \n",
       "8  20573.0    84.0      2.0    1.0  20160403     None  None       G       I   \n",
       "9  20555.0    55.0      2.0    1.0  20160403     None  None       G       N   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0    None       M   1962.0  07012016   None   None      VS  5.555625e+10   \n",
       "1    None       M   1942.0  07012016      F   None      VS  6.744065e+08   \n",
       "2    None       M   1972.0  10022016      M   None      VS  6.749482e+08   \n",
       "3    None       M   1978.0  07012016   None   None      VS  5.554176e+10   \n",
       "4    None    None   1952.0  07012016      F   None      VS  5.554133e+10   \n",
       "5    None    None   1953.0  07012016      M   None      BA  5.557804e+10   \n",
       "6    None       M   1972.0  07012016      M   None      BA  5.557892e+10   \n",
       "7    None       M   1977.0  07012016      M   None      BA  5.557874e+10   \n",
       "8    None       M   1932.0  07012016      M   None      BA  5.557746e+10   \n",
       "9    None       M   1961.0  07012016      M   None      BA  5.557787e+10   \n",
       "\n",
       "   fltno visatype  \n",
       "0  00115       WT  \n",
       "1    103       WT  \n",
       "2    109       B2  \n",
       "3  00103       WT  \n",
       "4  00103       WT  \n",
       "5  00227       WT  \n",
       "6  00227       WB  \n",
       "7  00227       WB  \n",
       "8  00227       WT  \n",
       "9  00227       WT  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a glance at the immigration data\n",
    "df_immi.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows in Immigration DataFrame: 2861188\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Rows in Immigration DataFrame: '+ str(df_immi.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immi.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### ----------------------------------------------------\n",
    "#### Data Dictionary- Immigration Data \n",
    "\n",
    "cicid: ID that uniquely identify each record\n",
    "\n",
    "I94YR: 4 digit year\n",
    "\n",
    "I94MON: Numeric month\n",
    "\n",
    "I94CIT: 3 digit code of source city for immigration (city of birth)\n",
    "\n",
    "I94RES: 3 digit code of source country for immigration (country of birth)\n",
    "\n",
    "I94PORT: Port addmitted through\n",
    "\n",
    "ARRDATE: Arrival date in the USA\n",
    "\n",
    "I94MODE: Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "\n",
    "I94ADDR: State of arrival\n",
    "\n",
    "DEPDATE: Departure date\n",
    "\n",
    "I94BIR: Age of immigrant in Years\n",
    "\n",
    "I94VISA: Visa codes collapsed into three categories: (1 = Business; 2 = Pleasure; 3 = Student)\n",
    "\n",
    "COUNT: count of rows (value of 1 assigned to each row)\n",
    "\n",
    "DTADFILE: Character Date Field\n",
    "\n",
    "VISAPOST: Department of State where where Visa was issued\n",
    "\n",
    "OCCUP: Occupation that will be performed in U.S.\n",
    "\n",
    "ENTDEPA: Arrival Flag. Whether admitted or paroled into the US\n",
    "\n",
    "ENTDEPD: Departure Flag. Whether departed, lost visa, or deceased\n",
    "\n",
    "ENTDEPU: Update Flag. Update of visa, either apprehended, overstayed, or updated to PR\n",
    "\n",
    "MATFLAG: Match flag\n",
    "\n",
    "BIRYEAR: 4 digit year of birth\n",
    "\n",
    "DTADDTO: Character date field to when admitted in the US\n",
    "\n",
    "GENDER: Gender\n",
    "\n",
    "INSNUM: INS number\n",
    "\n",
    "AIRLINE: Airline used to arrive in U.S.\n",
    "\n",
    "ADMNUM: Admission number, should be unique and not nullable\n",
    "\n",
    "FLTNO: Flight number of Airline used to arrive in U.S.\n",
    "\n",
    "VISATYPE: Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "\n",
    "##### -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.1 Airport Codes,     Country Code,     State Code,     Visa Code,     Travel Mode Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the csv data from S3\n",
    "df_airpt_code = spark.read.csv(csv_data_path + 'Airport_Code.csv', header = True, sep = ',')\n",
    "df_country_code = spark.read.csv(csv_data_path + 'Country_Code.csv', header = True,  sep = ',')\n",
    "df_state_code = spark.read.csv(csv_data_path + 'State_Code.csv', header = True,  sep = ',')\n",
    "df_visa_code = spark.read.csv(csv_data_path + 'Visa_Code.csv', header = True, sep = ',')\n",
    "df_travelMode_code = spark.read.csv(csv_data_path + 'Mode_of_Travel_Code.csv', header = True,  sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a collection (dictionary) of the codes data\n",
    "dict_codes = {'airport code': df_airpt_code,'country code': df_country_code,'state code': df_state_code,\\\n",
    "              'visa code': df_visa_code,'travel mode code': df_travelMode_code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport code : \n",
      "\n",
      "root\n",
      " |-- i94port_: string (nullable = true)\n",
      " |-- i94_airport_name_: string (nullable = true)\n",
      " |-- i94_state_: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "  i94port_         i94_airport_name_ i94_state_\n",
      "0      ALC                     ALCAN         AK\n",
      "1      ANC                 ANCHORAGE         AK\n",
      "2      BAR  BAKER AAF - BAKER ISLAND         AK\n",
      "\n",
      " --------- \n",
      "\n",
      "country code : \n",
      "\n",
      "root\n",
      " |-- i94cit_: string (nullable = true)\n",
      " |-- i94_country_: string (nullable = true)\n",
      " |-- iso_country_code_: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "  i94cit_ i94_country_ iso_country_code_\n",
      "0     582       MEXICO               484\n",
      "1     236  AFGHANISTAN                 4\n",
      "2     101      ALBANIA                 8\n",
      "\n",
      " --------- \n",
      "\n",
      "state code : \n",
      "\n",
      "root\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "  State_Code    State\n",
      "0         AL  ALABAMA\n",
      "1         AK   ALASKA\n",
      "2         AZ  ARIZONA\n",
      "\n",
      " --------- \n",
      "\n",
      "visa code : \n",
      "\n",
      "root\n",
      " |-- Code_Visa: string (nullable = true)\n",
      " |-- Visa_Name: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "  Code_Visa  Visa_Name\n",
      "0        1    Business\n",
      "1        2    Pleasure\n",
      "2        3     Student\n",
      "\n",
      " --------- \n",
      "\n",
      "travel mode code : \n",
      "\n",
      "root\n",
      " |-- Code_mode: string (nullable = true)\n",
      " |-- Mode_of_travel: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "  Code_mode Mode_of_travel\n",
      "0        1             Air\n",
      "1      \\t2             Sea\n",
      "2      \\t3            Land\n",
      "\n",
      " --------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# have a glance over the respective codes data\n",
    "for name, data in dict_codes.items():\n",
    "    print(name+' : \\n')\n",
    "    data.printSchema()\n",
    "    print('\\n')\n",
    "    print(data.limit(3).toPandas())\n",
    "    print('\\n --------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.1.2 Join the Codes data to immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join the 'state code' data with the immigration data because immigration data has the state code\n",
    "\n",
    "df_immi_state = df_immi.join(df_state_code, df_immi.i94addr == df_state_code.State_Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2736378"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi_state.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459651.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.555625e+10</td>\n",
       "      <td>00115</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459652.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.744065e+08</td>\n",
       "      <td>103</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459653.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20557.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10022016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.749482e+08</td>\n",
       "      <td>109</td>\n",
       "      <td>B2</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459655.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.554133e+10</td>\n",
       "      <td>00103</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459656.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557804e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459657.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557892e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459658.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557874e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>459659.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557746e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>459660.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557787e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>459661.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557773e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0  459651.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "1  459652.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "2  459653.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      FL   \n",
       "3  459655.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "4  459656.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "5  459657.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "6  459658.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "7  459659.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "8  459660.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "9  459661.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0      GA   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0  20559.0    54.0      2.0    1.0  20160403     None  None       O       R   \n",
       "1  20555.0    74.0      2.0    1.0  20160403     None  None       T       O   \n",
       "2  20557.0    44.0      2.0    1.0  20160403     None  None       T       Q   \n",
       "3      NaN    64.0      2.0    1.0  20160403     None  None       G    None   \n",
       "4      NaN    63.0      2.0    1.0  20160403     None  None       G    None   \n",
       "5  20548.0    44.0      1.0    1.0  20160403     None  None       G       I   \n",
       "6  20548.0    39.0      1.0    1.0  20160403     None  None       G       I   \n",
       "7  20573.0    84.0      2.0    1.0  20160403     None  None       G       I   \n",
       "8  20555.0    55.0      2.0    1.0  20160403     None  None       G       N   \n",
       "9  20555.0    54.0      2.0    1.0  20160403     None  None       G       N   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0    None       M   1962.0  07012016   None   None      VS  5.555625e+10   \n",
       "1    None       M   1942.0  07012016      F   None      VS  6.744065e+08   \n",
       "2    None       M   1972.0  10022016      M   None      VS  6.749482e+08   \n",
       "3    None    None   1952.0  07012016      F   None      VS  5.554133e+10   \n",
       "4    None    None   1953.0  07012016      M   None      BA  5.557804e+10   \n",
       "5    None       M   1972.0  07012016      M   None      BA  5.557892e+10   \n",
       "6    None       M   1977.0  07012016      M   None      BA  5.557874e+10   \n",
       "7    None       M   1932.0  07012016      M   None      BA  5.557746e+10   \n",
       "8    None       M   1961.0  07012016      M   None      BA  5.557787e+10   \n",
       "9    None       M   1962.0  07012016      M   None      BA  5.557773e+10   \n",
       "\n",
       "   fltno visatype State_Code    State  \n",
       "0  00115       WT         FL  FLORIDA  \n",
       "1    103       WT         FL  FLORIDA  \n",
       "2    109       B2         FL  FLORIDA  \n",
       "3  00103       WT         GA  GEORGIA  \n",
       "4  00227       WT         GA  GEORGIA  \n",
       "5  00227       WB         GA  GEORGIA  \n",
       "6  00227       WB         GA  GEORGIA  \n",
       "7  00227       WT         GA  GEORGIA  \n",
       "8  00227       WT         GA  GEORGIA  \n",
       "9  00227       WT         GA  GEORGIA  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data Frame\n",
    "df_immi_state.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop a redundant column\n",
    "df_immi_rev1 = df_immi_state.drop('i94addr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.3 Join (inner join) Airport Code, Country Code, and Visa Code to Immigration data\n",
    "\n",
    "![](Images\\dataModelPrelim.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## We have already Joined state data , thus we are joining the remaining three tables\n",
    "df_immi_joined = df_immi_rev1.join(df_airpt_code , df_immi_rev1.i94port == df_airpt_code.i94port_)\\\n",
    ".join(df_country_code , df_immi_rev1.i94cit == df_country_code.i94cit_)\\\n",
    ".join(df_visa_code , df_immi_rev1.i94visa == df_visa_code.Code_Visa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>State</th>\n",
       "      <th>i94port_</th>\n",
       "      <th>i94_airport_name_</th>\n",
       "      <th>i94_state_</th>\n",
       "      <th>i94cit_</th>\n",
       "      <th>i94_country_</th>\n",
       "      <th>iso_country_code_</th>\n",
       "      <th>Code_Visa</th>\n",
       "      <th>Visa_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459651.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.555625e+10</td>\n",
       "      <td>00115</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459652.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.744065e+08</td>\n",
       "      <td>103</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459653.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20557.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10022016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>6.749482e+08</td>\n",
       "      <td>109</td>\n",
       "      <td>B2</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459655.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VS</td>\n",
       "      <td>5.554133e+10</td>\n",
       "      <td>00103</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459656.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557804e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459657.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557892e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459658.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557874e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>459659.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557746e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>459660.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557787e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>459661.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.557773e+10</td>\n",
       "      <td>00227</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>135</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  459651.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "1  459652.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "2  459653.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "3  459655.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "4  459656.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "5  459657.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "6  459658.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "7  459659.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "8  459660.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "9  459661.0  2016.0     4.0   135.0   135.0     ATL  20547.0      1.0   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0  20559.0    54.0      2.0    1.0  20160403     None  None       O       R   \n",
       "1  20555.0    74.0      2.0    1.0  20160403     None  None       T       O   \n",
       "2  20557.0    44.0      2.0    1.0  20160403     None  None       T       Q   \n",
       "3      NaN    64.0      2.0    1.0  20160403     None  None       G    None   \n",
       "4      NaN    63.0      2.0    1.0  20160403     None  None       G    None   \n",
       "5  20548.0    44.0      1.0    1.0  20160403     None  None       G       I   \n",
       "6  20548.0    39.0      1.0    1.0  20160403     None  None       G       I   \n",
       "7  20573.0    84.0      2.0    1.0  20160403     None  None       G       I   \n",
       "8  20555.0    55.0      2.0    1.0  20160403     None  None       G       N   \n",
       "9  20555.0    54.0      2.0    1.0  20160403     None  None       G       N   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0    None       M   1962.0  07012016   None   None      VS  5.555625e+10   \n",
       "1    None       M   1942.0  07012016      F   None      VS  6.744065e+08   \n",
       "2    None       M   1972.0  10022016      M   None      VS  6.749482e+08   \n",
       "3    None    None   1952.0  07012016      F   None      VS  5.554133e+10   \n",
       "4    None    None   1953.0  07012016      M   None      BA  5.557804e+10   \n",
       "5    None       M   1972.0  07012016      M   None      BA  5.557892e+10   \n",
       "6    None       M   1977.0  07012016      M   None      BA  5.557874e+10   \n",
       "7    None       M   1932.0  07012016      M   None      BA  5.557746e+10   \n",
       "8    None       M   1961.0  07012016      M   None      BA  5.557787e+10   \n",
       "9    None       M   1962.0  07012016      M   None      BA  5.557773e+10   \n",
       "\n",
       "   fltno visatype State_Code    State i94port_ i94_airport_name_ i94_state_  \\\n",
       "0  00115       WT         FL  FLORIDA      ATL           ATLANTA         GA   \n",
       "1    103       WT         FL  FLORIDA      ATL           ATLANTA         GA   \n",
       "2    109       B2         FL  FLORIDA      ATL           ATLANTA         GA   \n",
       "3  00103       WT         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "4  00227       WT         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "5  00227       WB         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "6  00227       WB         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "7  00227       WT         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "8  00227       WT         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "9  00227       WT         GA  GEORGIA      ATL           ATLANTA         GA   \n",
       "\n",
       "  i94cit_    i94_country_ iso_country_code_ Code_Visa  Visa_Name  \n",
       "0     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "1     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "2     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "3     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "4     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "5     135  UNITED KINGDOM               826        1    Business  \n",
       "6     135  UNITED KINGDOM               826        1    Business  \n",
       "7     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "8     135  UNITED KINGDOM               826        2    Pleasure  \n",
       "9     135  UNITED KINGDOM               826        2    Pleasure  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi_joined.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- i94port_: string (nullable = true)\n",
      " |-- i94_airport_name_: string (nullable = true)\n",
      " |-- i94_state_: string (nullable = true)\n",
      " |-- i94cit_: string (nullable = true)\n",
      " |-- i94_country_: string (nullable = true)\n",
      " |-- iso_country_code_: string (nullable = true)\n",
      " |-- Code_Visa: string (nullable = true)\n",
      " |-- Visa_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immi_joined.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.4 Drop the columns which are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immi_dm = df_immi_joined.drop('i94cit','i94cit_','i94port','i94port_', 'insnum', 'airline', 'admnum', 'fltno', 'airline', 'matflag' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Convert arrival date and departure date columns to date time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define the function\n",
    "def convert_datetime(x):\n",
    "    \"\"\"\n",
    "    This function adds the number of days given in columns\n",
    "    arrdate and depdate to the standard date(1/1/1960) to get the \n",
    "    actual day, month, year of the date in datetime format.\n",
    "    \n",
    "    Arg:\n",
    "       x : data frame column having arrival date(arrdate) or departure date(depdate)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# create udf of the above defined function. \n",
    "\"\"\"\n",
    "This function further converts the datetime format from above function(convert_datetime()) \n",
    "to DateType format of the PySpark.\n",
    "\"\"\"\n",
    "udf_datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immi_dm = df_immi_dm.withColumn(\"arrival_date\", udf_datetime_from_sas(\"arrdate\"))\\\n",
    ".withColumn(\"departure_date\", udf_datetime_from_sas(\"depdate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>visatype</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>State</th>\n",
       "      <th>i94_airport_name_</th>\n",
       "      <th>i94_state_</th>\n",
       "      <th>i94_country_</th>\n",
       "      <th>iso_country_code_</th>\n",
       "      <th>Code_Visa</th>\n",
       "      <th>Visa_Name</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>departure_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459651.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20559.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>None</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459652.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459653.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20557.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>Q</td>\n",
       "      <td>None</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>10022016</td>\n",
       "      <td>M</td>\n",
       "      <td>B2</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459655.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>F</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459656.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459657.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459658.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>459659.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>I</td>\n",
       "      <td>None</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>459660.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>459661.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160403</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>07012016</td>\n",
       "      <td>M</td>\n",
       "      <td>WT</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>GA</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>826</td>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cicid   i94yr  i94mon  i94res  arrdate  i94mode  depdate  i94bir  \\\n",
       "0  459651.0  2016.0     4.0   135.0  20547.0      1.0  20559.0    54.0   \n",
       "1  459652.0  2016.0     4.0   135.0  20547.0      1.0  20555.0    74.0   \n",
       "2  459653.0  2016.0     4.0   135.0  20547.0      1.0  20557.0    44.0   \n",
       "3  459655.0  2016.0     4.0   135.0  20547.0      1.0      NaN    64.0   \n",
       "4  459656.0  2016.0     4.0   135.0  20547.0      1.0      NaN    63.0   \n",
       "5  459657.0  2016.0     4.0   135.0  20547.0      1.0  20548.0    44.0   \n",
       "6  459658.0  2016.0     4.0   135.0  20547.0      1.0  20548.0    39.0   \n",
       "7  459659.0  2016.0     4.0   135.0  20547.0      1.0  20573.0    84.0   \n",
       "8  459660.0  2016.0     4.0   135.0  20547.0      1.0  20555.0    55.0   \n",
       "9  459661.0  2016.0     4.0   135.0  20547.0      1.0  20555.0    54.0   \n",
       "\n",
       "   i94visa  count  dtadfile visapost occup entdepa entdepd entdepu  biryear  \\\n",
       "0      2.0    1.0  20160403     None  None       O       R    None   1962.0   \n",
       "1      2.0    1.0  20160403     None  None       T       O    None   1942.0   \n",
       "2      2.0    1.0  20160403     None  None       T       Q    None   1972.0   \n",
       "3      2.0    1.0  20160403     None  None       G    None    None   1952.0   \n",
       "4      2.0    1.0  20160403     None  None       G    None    None   1953.0   \n",
       "5      1.0    1.0  20160403     None  None       G       I    None   1972.0   \n",
       "6      1.0    1.0  20160403     None  None       G       I    None   1977.0   \n",
       "7      2.0    1.0  20160403     None  None       G       I    None   1932.0   \n",
       "8      2.0    1.0  20160403     None  None       G       N    None   1961.0   \n",
       "9      2.0    1.0  20160403     None  None       G       N    None   1962.0   \n",
       "\n",
       "    dtaddto gender visatype State_Code    State i94_airport_name_ i94_state_  \\\n",
       "0  07012016   None       WT         FL  FLORIDA           ATLANTA         GA   \n",
       "1  07012016      F       WT         FL  FLORIDA           ATLANTA         GA   \n",
       "2  10022016      M       B2         FL  FLORIDA           ATLANTA         GA   \n",
       "3  07012016      F       WT         GA  GEORGIA           ATLANTA         GA   \n",
       "4  07012016      M       WT         GA  GEORGIA           ATLANTA         GA   \n",
       "5  07012016      M       WB         GA  GEORGIA           ATLANTA         GA   \n",
       "6  07012016      M       WB         GA  GEORGIA           ATLANTA         GA   \n",
       "7  07012016      M       WT         GA  GEORGIA           ATLANTA         GA   \n",
       "8  07012016      M       WT         GA  GEORGIA           ATLANTA         GA   \n",
       "9  07012016      M       WT         GA  GEORGIA           ATLANTA         GA   \n",
       "\n",
       "     i94_country_ iso_country_code_ Code_Visa  Visa_Name arrival_date  \\\n",
       "0  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "1  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "2  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "3  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "4  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "5  UNITED KINGDOM               826        1    Business   2016-04-03   \n",
       "6  UNITED KINGDOM               826        1    Business   2016-04-03   \n",
       "7  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "8  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "9  UNITED KINGDOM               826        2    Pleasure   2016-04-03   \n",
       "\n",
       "  departure_date  \n",
       "0     2016-04-15  \n",
       "1     2016-04-11  \n",
       "2     2016-04-13  \n",
       "3           None  \n",
       "4           None  \n",
       "5     2016-04-04  \n",
       "6     2016-04-04  \n",
       "7     2016-04-29  \n",
       "8     2016-04-11  \n",
       "9     2016-04-11  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi_dm.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- i94_airport_name_: string (nullable = true)\n",
      " |-- i94_state_: string (nullable = true)\n",
      " |-- i94_country_: string (nullable = true)\n",
      " |-- iso_country_code_: string (nullable = true)\n",
      " |-- Code_Visa: string (nullable = true)\n",
      " |-- Visa_Name: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immi_dm.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.5 Write the immigration data to parquet files and store them in S3 Staging Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "df_immi_dm.write.parquet(staging_path+'immigration/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the US demographics data from S3\n",
    "df_demog = spark.read.csv(csv_data_path+'us-cities-demographics.csv', header=True, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows in Demographic DataFrame: 2891\n"
     ]
    }
   ],
   "source": [
    "# total number of rows\n",
    "print('Total Number of Rows in Demographic DataFrame: '+str(df_demog.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demog_state = df_demog.groupBy(['State']).agg({'Median Age': 'mean', 'Male Population': 'mean', \\\n",
    "                                                  'Female Population': 'mean', 'Number of Veterans': 'mean', \\\n",
    "                                                  'Foreign-born': 'mean', 'Average Household Size': 'mean',\\\n",
    "                                                  'State Code': 'First'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>avg(Female Population)</th>\n",
       "      <th>avg(Median Age)</th>\n",
       "      <th>first(State Code)</th>\n",
       "      <th>avg(Number of Veterans)</th>\n",
       "      <th>avg(Foreign-born)</th>\n",
       "      <th>avg(Male Population)</th>\n",
       "      <th>avg(Average Household Size)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utah</td>\n",
       "      <td>52769.270833</td>\n",
       "      <td>30.862500</td>\n",
       "      <td>UT</td>\n",
       "      <td>4024.270833</td>\n",
       "      <td>13579.395833</td>\n",
       "      <td>53890.666667</td>\n",
       "      <td>3.156875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>175959.000000</td>\n",
       "      <td>41.400000</td>\n",
       "      <td>HI</td>\n",
       "      <td>23213.000000</td>\n",
       "      <td>101312.000000</td>\n",
       "      <td>176807.000000</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>66025.222222</td>\n",
       "      <td>35.579630</td>\n",
       "      <td>MN</td>\n",
       "      <td>5958.111111</td>\n",
       "      <td>19812.740741</td>\n",
       "      <td>64422.277778</td>\n",
       "      <td>2.496852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>127414.204082</td>\n",
       "      <td>35.593878</td>\n",
       "      <td>OH</td>\n",
       "      <td>12927.673469</td>\n",
       "      <td>17834.510204</td>\n",
       "      <td>119454.163265</td>\n",
       "      <td>2.298571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>51109.137931</td>\n",
       "      <td>32.737931</td>\n",
       "      <td>AR</td>\n",
       "      <td>5323.793103</td>\n",
       "      <td>10612.172414</td>\n",
       "      <td>48300.827586</td>\n",
       "      <td>2.526897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  avg(Female Population)  avg(Median Age) first(State Code)  \\\n",
       "0       Utah            52769.270833        30.862500                UT   \n",
       "1     Hawaii           175959.000000        41.400000                HI   \n",
       "2  Minnesota            66025.222222        35.579630                MN   \n",
       "3       Ohio           127414.204082        35.593878                OH   \n",
       "4   Arkansas            51109.137931        32.737931                AR   \n",
       "\n",
       "   avg(Number of Veterans)  avg(Foreign-born)  avg(Male Population)  \\\n",
       "0              4024.270833       13579.395833          53890.666667   \n",
       "1             23213.000000      101312.000000         176807.000000   \n",
       "2              5958.111111       19812.740741          64422.277778   \n",
       "3             12927.673469       17834.510204         119454.163265   \n",
       "4              5323.793103       10612.172414          48300.827586   \n",
       "\n",
       "   avg(Average Household Size)  \n",
       "0                     3.156875  \n",
       "1                     2.690000  \n",
       "2                     2.496852  \n",
       "3                     2.298571  \n",
       "4                     2.526897  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog_state.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog_state.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- avg(Female Population): double (nullable = true)\n",
      " |-- avg(Median Age): double (nullable = true)\n",
      " |-- first(State Code): string (nullable = true)\n",
      " |-- avg(Number of Veterans): double (nullable = true)\n",
      " |-- avg(Foreign-born): double (nullable = true)\n",
      " |-- avg(Male Population): double (nullable = true)\n",
      " |-- avg(Average Household Size): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demog_state.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Rename the columns else there will be an error, because column names cannot contain brackets '()'\n",
    "\n",
    "df_demog_dm = df_demog_state.withColumnRenamed('avg(Female Population)', 'avgFemalePopulation').withColumnRenamed('avg(Median Age)', 'avgMedianAge')\\\n",
    ".withColumnRenamed('first(State Code)', 'stateCode').withColumnRenamed('avg(Number of Veterans)', 'avgNumberOfVeterans')\\\n",
    ".withColumnRenamed('avg(Foreign-born)', 'avgForeignBorn').withColumnRenamed('avg(Male Population)', 'avgMalePopulation')\\\n",
    ".withColumnRenamed('avg(Average Household Size)', 'avgHouseHoldSize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- avgFemalePopulation: double (nullable = true)\n",
      " |-- avgMedianAge: double (nullable = true)\n",
      " |-- stateCode: string (nullable = true)\n",
      " |-- avgNumberOfVeterans: double (nullable = true)\n",
      " |-- avgForeignBorn: double (nullable = true)\n",
      " |-- avgMalePopulation: double (nullable = true)\n",
      " |-- avgHouseHoldSize: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demog_dm.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Convert the State column to Upper case; because we need to join the immigration data to States Demographic data.\n",
    "\n",
    "## We can also convert this data frame entirely to Pandas and apply functions because this data frame is very small.\n",
    "\n",
    "df_demog_upper = to_upper_case_(df_demog_dm.toPandas(), 'State', 'State_upper_case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgFemalePopulation</th>\n",
       "      <th>avgMedianAge</th>\n",
       "      <th>stateCode</th>\n",
       "      <th>avgNumberOfVeterans</th>\n",
       "      <th>avgForeignBorn</th>\n",
       "      <th>avgMalePopulation</th>\n",
       "      <th>avgHouseHoldSize</th>\n",
       "      <th>State_upper_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52769.270833</td>\n",
       "      <td>30.862500</td>\n",
       "      <td>UT</td>\n",
       "      <td>4024.270833</td>\n",
       "      <td>13579.395833</td>\n",
       "      <td>53890.666667</td>\n",
       "      <td>3.156875</td>\n",
       "      <td>UTAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175959.000000</td>\n",
       "      <td>41.400000</td>\n",
       "      <td>HI</td>\n",
       "      <td>23213.000000</td>\n",
       "      <td>101312.000000</td>\n",
       "      <td>176807.000000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66025.222222</td>\n",
       "      <td>35.579630</td>\n",
       "      <td>MN</td>\n",
       "      <td>5958.111111</td>\n",
       "      <td>19812.740741</td>\n",
       "      <td>64422.277778</td>\n",
       "      <td>2.496852</td>\n",
       "      <td>MINNESOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127414.204082</td>\n",
       "      <td>35.593878</td>\n",
       "      <td>OH</td>\n",
       "      <td>12927.673469</td>\n",
       "      <td>17834.510204</td>\n",
       "      <td>119454.163265</td>\n",
       "      <td>2.298571</td>\n",
       "      <td>OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51109.137931</td>\n",
       "      <td>32.737931</td>\n",
       "      <td>AR</td>\n",
       "      <td>5323.793103</td>\n",
       "      <td>10612.172414</td>\n",
       "      <td>48300.827586</td>\n",
       "      <td>2.526897</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avgFemalePopulation  avgMedianAge stateCode  avgNumberOfVeterans  \\\n",
       "0         52769.270833     30.862500        UT          4024.270833   \n",
       "1        175959.000000     41.400000        HI         23213.000000   \n",
       "2         66025.222222     35.579630        MN          5958.111111   \n",
       "3        127414.204082     35.593878        OH         12927.673469   \n",
       "4         51109.137931     32.737931        AR          5323.793103   \n",
       "\n",
       "   avgForeignBorn  avgMalePopulation  avgHouseHoldSize State_upper_case  \n",
       "0    13579.395833       53890.666667          3.156875             UTAH  \n",
       "1   101312.000000      176807.000000          2.690000           HAWAII  \n",
       "2    19812.740741       64422.277778          2.496852        MINNESOTA  \n",
       "3    17834.510204      119454.163265          2.298571             OHIO  \n",
       "4    10612.172414       48300.827586          2.526897         ARKANSAS  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog_upper.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Write the state level demographic data for cities only (aggregated) to parquet files and store them in S3 Staging Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert the pandas data frame back to spark dataframe. \n",
    "df_demog_dim = spark.createDataFrame(df_demog_upper)\n",
    "\n",
    "# write to paraquet and store it in S3 Staging Bucket\n",
    "df_demog_dim.write.parquet(staging_path+'demography/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3 Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read temperature data\n",
    "df_temp = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Rows in Temperature DataFrame: 8599212\n"
     ]
    }
   ],
   "source": [
    "# total number of rows\n",
    "print('Total Number of Rows in Temperature DataFrame: '+str(df_temp.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## lets us aggregate the data to the Country Level\n",
    "df_temp_country = df_temp.groupby([\"Country\"]).agg({\"AverageTemperature\": 'mean', \"Latitude\": 'First', \"Longitude\": \"First\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- avg(AverageTemperature): double (nullable = true)\n",
      " |-- first(Latitude): string (nullable = true)\n",
      " |-- first(Longitude): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp_country.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp_dm = df_temp_country.withColumnRenamed('avg(AverageTemperature)', 'avgTemperature').withColumnRenamed('first(Latitude)', 'Latitude').withColumnRenamed('first(Longitude)', 'Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_dm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Convert the Country column to Upper case; because we need to join the immigration data to Temperature data\n",
    "\n",
    "df_temp_upper = to_upper_case_(df_temp_dm.toPandas(), 'Country', 'Country_upper_case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Country_upper_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.189829</td>\n",
       "      <td>8.84N</td>\n",
       "      <td>15.41E</td>\n",
       "      <td>CHAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.784014</td>\n",
       "      <td>24.92S</td>\n",
       "      <td>58.52W</td>\n",
       "      <td>PARAGUAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.347268</td>\n",
       "      <td>53.84N</td>\n",
       "      <td>91.36E</td>\n",
       "      <td>RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.768408</td>\n",
       "      <td>13.66N</td>\n",
       "      <td>45.41E</td>\n",
       "      <td>YEMEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.984177</td>\n",
       "      <td>15.27N</td>\n",
       "      <td>17.50W</td>\n",
       "      <td>SENEGAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avgTemperature Latitude Longitude Country_upper_case\n",
       "0       27.189829    8.84N    15.41E               CHAD\n",
       "1       22.784014   24.92S    58.52W           PARAGUAY\n",
       "2        3.347268   53.84N    91.36E             RUSSIA\n",
       "3       25.768408   13.66N    45.41E              YEMEN\n",
       "4       25.984177   15.27N    17.50W            SENEGAL"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_upper.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Write the Country level temperature data to parquet files and store them in S3 Staging Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp_dim = spark.createDataFrame(df_temp_upper)\n",
    "\n",
    "df_temp_dim.write.parquet(staging_path+'temperature/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we can also partition our data by countries :    df_temp_dm.write.partitionBy(\"Country\").parquet(staging_path+'temperature/')\n",
    "# to store the data partitioned by countries. It is a good practice to partion the bigger data because it helps in optimizing the query performance. \n",
    "# Here, we are not doing the partition because our data is already very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "**Fact_Immigration**: Immigration table is our central table, which consist of events that we need to analyze, thus, this table  acts as a fact table in our star schema. The immigration data has already been joined with the state code, country code, Visa code and port code tables; these tables were joined previously to the immigration table because after joining these tables(country code and state code), we get the State and Country names corresponding to the codes.\n",
    "\n",
    "**Dim_Temperature**: The level of granularity in the raw temperature table data is to the level of city in the country of origin. Since our fact table doesnt have that level of granularity, thus I have aggregated the temperature data to the level of granularity of the country. Thus I have aggregated the temperature data to the level of Country. This transformed table gives us the average temperature in the country of origin of an immigrant.\n",
    "\n",
    "**Dim_Demography**: Raw/original demographic data was given at the city level; however, I have changed the granularity of the original table to the State level. This would help us in joining the immigration table to the demography table on the State column. The aggregation of the city level data to the state level data can be understood from the example given below :                                       \n",
    "*Original table*: The column 'Male Population' represented male population in a particular city of a State in USA.                           \n",
    "*Transformed table*: The column 'avgMalePopulation' represents the average population aggregated across all the given citiese in a particular State in USA.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![](Images\\StartSchema.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**The whole pipeline is divided into two phases: phase 1 and phase 2.**\n",
    "\n",
    "![](Images\\architecture1.PNG)\n",
    "\n",
    "**Phase1 :** In this phase we did the extraction of raw data, transformation to process the data, and loading of the data to S3 Staging folder. We used **EMR Spark cluster** to this phase.     \n",
    "1. Extracted data from the repository (S3 bucket 1).\n",
    "2. Joined immigration table with all the State, Visa, Port codes to the Immigration table.\n",
    "3. Saved the processed Immigration Table into the Staging Bucket (S3 bucket 2) in Parquet format.\n",
    "4. Extracted raw temperature data from the repository.\n",
    "5. Processed the raw temperature table by aggregating the temperature table at the level of detail of the Country.\n",
    "6. Saved the processed Temperature table to the Staging Bucket (S3 bucket 2).\n",
    "7. Extracted raw demographic data.\n",
    "8. Processed the raw demographic data by aggregating the data to the granularity of the States. \n",
    "9. Saved the processed demography table to the Staging Bucket (S3 bucket 2)\n",
    "\n",
    "**Phase2 :** In this phase we extracted the data from the Staging Bucket (S3 Bucket 2) and loaded them into the **Redshift** data warehouse.\n",
    "1. Created the data model in Redshift with all the integrity constraints.\n",
    "2. Copied the data from the Staging Bucket to the Redshift cluster.\n",
    "3. Performed Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.1 AWS Credential variables declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Save the credentials in the form of variables for programmatically accessing Redshift\n",
    "\n",
    "KEY                    = config.get('AWS','AWS_ACCESS_KEY_ID')\n",
    "SECRET                 = config.get('AWS','AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "IAM_ROLE               = config.get(\"IAM_ROLE\",\"ARN\")\n",
    "HOST                   = config.get(\"CLUSTER\",\"HOST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.2 Create AWS resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Create an object s3 through which we can access the s3 buckets in aws.\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "## Create an object iam through which we can access the iam roles in aws. \n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "## Create an object redshift through which we can access redshift in aws. \n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.3 Connection with Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## write Connection query with redshift\n",
    "\n",
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, HOST, DWH_PORT, DWH_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: awsuser@dev'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Connect to redshift using sql. Execute the query.\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.4 Drop pre-existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop Tables query\n",
    "\n",
    "immigration_table_drop         = \"DROP TABLE IF EXISTS fact_immigration\"\n",
    "temperature_table_drop         = \"DROP TABLE IF EXISTS dim_temperature\"\n",
    "demography_table_drop          = \"DROP TABLE IF EXISTS dim_demography\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the drop table query\n",
    "\n",
    "%sql $immigration_table_drop\n",
    "%sql $temperature_table_drop\n",
    "%sql $demography_table_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.5 Create Data Model in Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create data model in Redshift\n",
    "\n",
    "immigration_fact_table_create= (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS fact_immigration\n",
    "(\n",
    " cicid             FLOAT       PRIMARY KEY,\n",
    " i94yr             FLOAT,\n",
    " i94mon            FLOAT,\n",
    " i94res            FLOAT, \n",
    " arrdate           FLOAT, \n",
    " i94mode           FLOAT, \n",
    " depdate           FLOAT, \n",
    " i94bir            FLOAT, \n",
    " i94visa           FLOAT, \n",
    " count             FLOAT, \n",
    " dtadfile          VARCHAR, \n",
    " visapost          VARCHAR, \n",
    " occup             VARCHAR, \n",
    " entdepa           VARCHAR, \n",
    " entdepd           VARCHAR, \n",
    " entdepu           VARCHAR, \n",
    " biryear           FLOAT, \n",
    " dtaddto           VARCHAR, \n",
    " gender            VARCHAR, \n",
    " visatype          VARCHAR, \n",
    " State_Code        VARCHAR, \n",
    " State             VARCHAR,\n",
    " i94_airport_name_ VARCHAR,\n",
    " i94_state_        VARCHAR, \n",
    " i94_country_      VARCHAR,\n",
    " iso_country_code_ VARCHAR, \n",
    " Code_Visa         VARCHAR, \n",
    " Visa_Name         VARCHAR,\n",
    " arrival_date      DATE,\n",
    " departure_date    DATE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "temperature_dim_table_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dim_temperature\n",
    "(\n",
    "     AverageTemperature     FLOAT,\n",
    "     Latitude               VARCHAR,\n",
    "     Longitude              VARCHAR,\n",
    "     Country_upper_case     VARCHAR  PRIMARY KEY\n",
    "     )\n",
    "diststyle all;\n",
    "\"\"\")\n",
    "\n",
    "demography_dim_table_create = (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dim_demography\n",
    "(\n",
    "     avgFemalePopulation       FLOAT, \n",
    "     avgMedianAge              FLOAT,\n",
    "     StateCode                 VARCHAR  NOT NULL, \n",
    "     avgNumberOfVeterans       FLOAT,\n",
    "     avgForeignBorn            FLOAT, \n",
    "     avgMalePopulation         FLOAT,\n",
    "     avgAverageHouseholdSize   FLOAT,\n",
    "     State_upper_case          VARCHAR  PRIMARY KEY\n",
    ")\n",
    "diststyle all;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute sql query variables declared above\n",
    "\n",
    "%sql $immigration_fact_table_create\n",
    "%sql $temperature_dim_table_create\n",
    "%sql $demography_dim_table_create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.6 Copy data from Staging Bucket to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copy data to redshift: sql query variables\n",
    "\n",
    "immi_data_to_redshift= \"\"\"COPY fact_immigration\n",
    "                          FROM 's3://staging-ap/immigration/'\n",
    "                          CREDENTIALS 'aws_iam_role=arn:aws:iam::392638740494:role/dwhRole'\n",
    "                          FORMAT AS PARQUET; \"\"\"\n",
    "\n",
    "demog_data_to_redshift= \"\"\"COPY dim_demography\n",
    "                           FROM 's3://staging-ap/demography/'\n",
    "                           CREDENTIALS 'aws_iam_role=arn:aws:iam::392638740494:role/dwhRole'\n",
    "                           FORMAT AS PARQUET; \"\"\"\n",
    "\n",
    "temp_data_to_redshift= \"\"\"COPY dim_temperature\n",
    "                          FROM 's3://staging-ap/temperature/'\n",
    "                          CREDENTIALS 'aws_iam_role=arn:aws:iam::392638740494:role/dwhRole'\n",
    "                          FORMAT AS PARQUET; \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n",
      " * postgresql://awsuser:***@redshift-cluster-1.czg1ucux6cgx.us-west-2.redshift.amazonaws.com:5439/dev\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute Sql query variable declared above\n",
    "\n",
    "%sql $demog_data_to_redshift\n",
    "\n",
    "%sql $temp_data_to_redshift\n",
    "\n",
    "%sql $immi_data_to_redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.0 *Before running the query we should know that to assign a variable to the output of the sql query we need to assign a variable to the output. For this we need to run the query in python rather than running in the SQl environment of python jupyter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# establish Connection to the redshift/database\n",
    "con = psycopg2.connect(dbname= DWH_DB , host= HOST,port= DWH_PORT, user= DWH_DB_USER, password= DWH_DB_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a cursor\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.1 Check whether we are getting any data in facts and dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immi_data_check = \"\"\" select count(*) from fact_immigration;\"\"\"\n",
    "\n",
    "demo_data_check = \"\"\" select count(*) from dim_demography  ;\"\"\"\n",
    "\n",
    "temp_data_check = \"\"\" select count(*) from dim_temperature ;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of Variables\n",
    "checks = {'fact_immigration':immi_data_check,'dim_demography':demo_data_check,'dim_temperature':temp_data_check}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Checked : Ok\n"
     ]
    }
   ],
   "source": [
    "# actual checks\n",
    "num = 0\n",
    "prob = []\n",
    "for table_name, table_query in checks.items():\n",
    "    cur.execute(table_query)\n",
    "    if cur.fetchall()[0][0] != 0:\n",
    "        continue\n",
    "    else:\n",
    "        num = num +1\n",
    "        prob.append(table_name)\n",
    "    \n",
    "\n",
    "# results\n",
    "if num > 0:\n",
    "    for i in prob:\n",
    "        print('No data found in the table : {}'.format(i))\n",
    "else:\n",
    "    print('Quality Checked : Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Close the connection and cursor\n",
    "\n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "##### --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " #### fact_immigration table\n",
    "##### --------------------------------------\n",
    " \n",
    " cicid        :         ID that uniquely identify each record\n",
    " \n",
    " i94yr        :        4 digit year\n",
    " \n",
    " i94mon       :       Numeric month\n",
    " \n",
    " i94res       :      country of birth\n",
    " \n",
    " arrdate      :     Arrival date in the USA\n",
    " \n",
    " i94mode      :    Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    " \n",
    " depdate      :     Departure date\n",
    " \n",
    " i94bir       :    Age of Respondent in Years\n",
    " \n",
    " i94visa      :    Visa codes collapsed into three categories: (1 = Business; 2 = Pleasure; 3 = Student)\n",
    " \n",
    " count        :    count of rows (1  for each row)\n",
    " \n",
    " dtadfile     :    Character Date Field\n",
    " \n",
    " visapost     :     Post /State where Visa issued \n",
    " \n",
    " occup        :     Occupation that will be performed in U.S.\n",
    " \n",
    " entdepa      :      Arrival Flag. Whether admitted or paroled into the US\n",
    " \n",
    " entdepd      :     Departure Flag. Whether departed, lost visa, or deceased\n",
    " \n",
    " entdepu      :     Update Flag. Update of visa, either apprehended, overstayed, or updated to PR\n",
    " \n",
    " biryear      :     year of birth\n",
    " \n",
    " dtaddto      :     Character date field to when admitted in the US\n",
    " \n",
    " gender       :      Gender\n",
    " \n",
    " visatype     :     Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    " \n",
    " State_Code   :     Code for States in USA\n",
    " \n",
    " State        :     Name of States in USA\n",
    " \n",
    " i94_airport_name_  :   Airport Name\n",
    " \n",
    " i94_state_    :    State Code\n",
    " \n",
    " i94_country_   :   Country of Origin\n",
    " \n",
    " iso_country_code_     : Country of Origin Code\n",
    " \n",
    " Code_Visa     :    Code related to visa type\n",
    " \n",
    " Visa_Name      :   Name of Visa Type\n",
    " \n",
    " arrival_date   :   Arrival Date in USA\n",
    " \n",
    " departure_date  :  Departure Date in USA\n",
    "##### --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### dim_demography table\n",
    "##### --------------------------------------\n",
    "\n",
    "State_upper_case: Name of the State in upper case letters\n",
    "\n",
    "avgFemalePopulation :  Avergae Female Population in a state\n",
    "\n",
    "avgMedianAge :  Avergae of Median Ages in the cities in a state\n",
    "\n",
    "stateCode:      State Code\n",
    "\n",
    "avgNumberOfVeterans: Average Number of Veterans in the state\n",
    "\n",
    "avgForeignBorn:   Average Forein Born Population in a state\n",
    "\n",
    "avgMalePopulation: Average Male Population in a state\n",
    "\n",
    "avgHouseHoldSize:  Average House Hold Size in the state\n",
    "\n",
    "##### --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### dim_temperature table\n",
    "##### --------------------------------------\n",
    "\n",
    "Country_upper_case  :   Country Name in Upper Case\n",
    "\n",
    "AverageTemperature  :   Average Temperature in the Country\n",
    "\n",
    "Latitude            :   Latitude\n",
    "\n",
    "Longitude           :   Longitude\n",
    "\n",
    "##### ==============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    " ##### --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "*We have used the AWS cloud technology, because it is low cost, highly, scalable and reliable in comparison to on premise or hybrid technologies available to us. This solution has been built keeping in future growth of data in mind. All the AWS services used in this solution are scalable and low cost.*\n",
    "\n",
    "AWS Services and their justifications are mentioned below:\n",
    "\n",
    "**S3**: S3 Buckets have been used for several purposes such as  Data lake, Staging Area, and for saving the query results from redshift. It can easily be integrated with EMR and Redshift services as a massive storage of data. Data accessibility is super easy. Other than that, S3 is cheap, easy-to-use, highly scalabe, highly available, and secured.\n",
    "\n",
    "**Spark**: The existing data from the client was big and keeping future data growth in mind, we can assume that its going to grow at even more rapid pace. Therefore, we needed the best big data processing framework, and that is Spark, which is not only very fast as compared to other such systems but also scalable and fault tolerant. since python is the most popular programming language among the data scientists and engineers, thus I have used python API(PySpark) of spark to do the data processing.\n",
    "\n",
    "**EMR**: We have divided the pipeline in two stages: one is for processing the massive data and the other is meant to create a data warehouse for querying the data using BI apps using SQL. We have used EMR to process raw data and store them in Staging Bucket in S3.  We have used EMR because it is the industry leading cloud-native big data platform for processing vast amounts of data quickly and cost-effectively at scale. Using open source tools such as Apache Spark coupled with the dynamic scalability of Amazon EC2 and scalable storage of Amazon S3, EMR gives analytical teams the engines and elasticity to run Petabyte-scale analysis for a fraction of the cost of traditional on-premises clusters.\n",
    "\n",
    "**Redshift**: Amazon Redshift is the most popular and fastest cloud data warehouse. Redshift is integrated with our data lake (S3), offers up to 3x faster performance than any other data warehouse, and costs up to 75% less than any other cloud data warehouse. The client can query data in Redshift using popular SQL language.\n",
    "\n",
    " ##### --------------------------------------------------------------------\n",
    "\n",
    "**Propose how often the data should be updated and why**\n",
    "\n",
    "We get data per month  Thus it is reasonable to update the model monthly.\n",
    "\n",
    "**Write a description of how you would approach the problem differently under the following scenarios:**\n",
    "\n",
    "**The data was increased by 100x:**\n",
    "\n",
    "Scalability is not an issue at all with this solution. If we have to scale , then we just need to increase the number of nodes of the cluster in EMR.\n",
    "\n",
    "\n",
    "**The data populates a dashboard that must be updated on a daily basis by 7am every day.**:\n",
    "\n",
    "We can create an airflow dag with a scheduled running time interval daily so that our data is updated before 7AM daily.\n",
    "\n",
    "**The database needed to be accessed by 100+ people**:\n",
    "\n",
    "Amazon Redshift provides consistently fast performance, even with thousands of concurrent queries, whether they query data in your Amazon Redshift data warehouse, or directly in your Amazon S3 data lake. Amazon Redshift Concurrency Scaling supports virtually unlimited concurrent users and concurrent queries with consistent service levels by adding transient capacity in seconds as concurrency increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### ========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
